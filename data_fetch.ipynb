{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to fetch data from the website\n",
    "# using beautifulsoup, requests and pandas\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import grequests\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imo = requests.get('https://www.imovirtual.com/arrendar/apartamento/') # request http\n",
    "raw_html = imo.text # convert webpage code into raw text\n",
    "soup = bs(raw_html) # soupify page text\n",
    "\n",
    "# find number of pages\n",
    "for i in soup.find_all('ul', class_='pager'):\n",
    "    pages = int(i.text.split()[-1])\n",
    "    \n",
    "# initialize url list with first page for subsequent appending \n",
    "urls = ['https://www.imovirtual.com/arrendar/apartamento/'] \n",
    "\n",
    "# append further pages links\n",
    "for page in range(2,pages+1):\n",
    "    urls.append('https://www.imovirtual.com/arrendar/apartamento/?page=' + str(page))\n",
    "    \n",
    "# initialize lists for house prices, types, locations and sizes. We'll also store links\n",
    "prices = []\n",
    "types = []\n",
    "location = []\n",
    "sizes = [] \n",
    "links = []\n",
    "\n",
    "for u in urls:\n",
    "    imo = requests.get(u) # request http\n",
    "    raw_html = imo.text # convert webpage code into raw text\n",
    "    soup = bs(raw_html) # soupify page text\n",
    "\n",
    "    # Find the desired data: price, location (concelho), typology and size (m2)\n",
    "\n",
    "    # price\n",
    "    for price in soup.find_all('li', class_=\"offer-item-price\"): \n",
    "        prices.append(price.string.split('€')[0].replace(' ','').strip())\n",
    "\n",
    "    #type \n",
    "    for ty in soup.find_all('li', class_=\"offer-item-rooms hidden-xs\"):\n",
    "        types.append(ty.string)\n",
    "\n",
    "    #location\n",
    "    for loc in soup.find_all('p', class_=\"text-nowrap\"):\n",
    "        location.append(loc.text.split('Apartamento para arrendar: ')[1])\n",
    "\n",
    "    #size (m2)\n",
    "    for size in soup.find_all('li', class_=\"hidden-xs offer-item-area\"):\n",
    "        sizes.append(size.next.split(' ')[0]) \n",
    "        \n",
    "    for link in soup.find_all('header', class_=\"offer-item-header\"):\n",
    "        links.append(link.a['href'])\n",
    "        \n",
    "all_houses = [] # list where all houses will be\n",
    "all_houses.append([prices, types, location, sizes, links])\n",
    "columns = ['price','type','location','size','link'] # columns names for the dataframe\n",
    "all_data = pd.DataFrame(all_houses[0]) # create datafame with the list created\n",
    "all_data = all_data.transpose() # transpose dataframe\n",
    "all_data.columns = columns # rename dataframe columns\n",
    "all_data = all_data.drop_duplicates() # drop duplicate columns\n",
    "all_data = all_data[all_data['price'] != 'Preçosobconsulta'] # drop houses with negotiable prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace house types with numeric values       \n",
    "type_dict = {'T2':2, 'T3':3, 'T1':1, 'T4':4, 'T0':0, 'T5':5, 'T6':6, 'T8':8, 'T7':7, 'T10 ou superior':10, 'T9':9}\n",
    "all_data['type'] = all_data['type'].replace(type_dict)\n",
    "\n",
    "# split location into municipality and district columns\n",
    "municipality = []\n",
    "district = []\n",
    "for i in all_data.location.str.split(', '):\n",
    "    try:\n",
    "        municipality.append(i[-2])\n",
    "    except:\n",
    "        municipality.append(i[-1])\n",
    "        \n",
    "    try:\n",
    "        district.append(i[-1])\n",
    "    except:\n",
    "        district.append('')\n",
    "\n",
    "all_data['municipality'] = municipality\n",
    "all_data['district'] = district\n",
    "all_data = all_data.drop(columns='location', axis=1)\n",
    "\n",
    "# change size column to float and price to int\n",
    "all_data['size'] = all_data['size'].replace(',','.', regex=True).astype('float')\n",
    "all_data['price'] = all_data['price'].replace(',','.', regex=True).astype('float').round().astype('int')\n",
    "\n",
    "\n",
    "# reset index to match number of posts\n",
    "all_data = all_data.reset_index()\n",
    "\n",
    "# save data to local csv file\n",
    "all_data.to_csv('house_data.csv', index=False)\n",
    "all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
